{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rasecfaria/FinalProject/blob/main/v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JR9xxpMPQq9J"
   },
   "source": [
    "# Movie Recommendation System üé¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8cbD_CpQq9J"
   },
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjNMw7yAQq9K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re  # Adicionando para extra√ß√£o do ano dos t√≠tulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t5ZuwXnQq9K"
   },
   "source": [
    "### Step 2: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdZLD1QNQq9L"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/ratings.csv')\n",
    "movies = pd.read_csv('data/movies.csv')\n",
    "\n",
    "# Fun√ß√£o para extrair o ano do t√≠tulo do filme\n",
    "def extract_year(title):\n",
    "    # Procurar pelo ano entre par√™nteses no final do t√≠tulo\n",
    "    match = re.search(r'\\((\\d{4})\\)$', title)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Adicionar coluna de ano ao DataFrame de filmes\n",
    "movies['year'] = movies['title'].apply(extract_year)\n",
    "\n",
    "# Calcular a distribui√ß√£o de anos para entender a faixa de anos nos dados\n",
    "year_counts = movies['year'].value_counts().sort_index()\n",
    "min_year = movies['year'].min()\n",
    "max_year = movies['year'].max()\n",
    "\n",
    "print(f\"Anos dos filmes: de {min_year} at√© {max_year}\")\n",
    "print(f\"Total de filmes com ano identificado: {movies['year'].count()}\")\n",
    "print(f\"Filmes sem ano identificado: {movies['year'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51_WdWRhQq9L"
   },
   "source": [
    "### Step 3: Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raKmITnWQq9L",
    "outputId": "b4046daf-0e16-4d98-bdd6-94e942106d80"
   },
   "outputs": [],
   "source": [
    "n_ratings = len(ratings)\n",
    "n_movies = ratings['movieId'].nunique()\n",
    "n_users = ratings['userId'].nunique()\n",
    "\n",
    "print(f\"Number of ratings: {n_ratings}\")\n",
    "print(f\"Number of unique movies: {n_movies}\")\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Average number of ratings per user: {round(n_ratings/n_users, 2)}\")\n",
    "print(f\"Average number of ratings per movie: {round(n_ratings/n_movies, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b: Normaliza√ß√£o Centrada na M√©dia\n",
    "\n",
    "A normaliza√ß√£o centrada na m√©dia consiste em ajustar as avalia√ß√µes de cada usu√°rio subtraindo a m√©dia de suas avalia√ß√µes. Isso ajuda a corrigir o vi√©s de alguns usu√°rios que tendem a dar avalia√ß√µes consistentemente mais altas ou mais baixas que outros.\n",
    "\n",
    "A normaliza√ß√£o √© complementar √† m√©dia bayesiana. Enquanto a m√©dia bayesiana ajuda a classificar filmes com poucas avalia√ß√µes, a normaliza√ß√£o ajuda a alinhar as escalas de avalia√ß√£o entre diferentes usu√°rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(df):\n",
    "    \"\"\"\n",
    "    Normaliza as avalia√ß√µes subtraindo a m√©dia de avalia√ß√£o de cada usu√°rio.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame pandas contendo pelo menos 3 colunas (userId, movieId, rating)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame normalizado contendo as colunas originais e uma coluna adicional 'rating_normalized'\n",
    "    \"\"\"\n",
    "    # Calcula a m√©dia de avalia√ß√£o de cada usu√°rio\n",
    "    user_mean_ratings = df.groupby('userId')['rating'].mean()\n",
    "    \n",
    "    # Cria uma c√≥pia do DataFrame original\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Adiciona a coluna com as avalia√ß√µes normalizadas\n",
    "    df_normalized['rating_normalized'] = df_normalized.apply(\n",
    "        lambda x: x['rating'] - user_mean_ratings[x['userId']], \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# Aplicar normaliza√ß√£o nas avalia√ß√µes\n",
    "ratings_normalized = normalize_ratings(ratings)\n",
    "\n",
    "# Mostrar as primeiras linhas para verificar\n",
    "ratings_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_X(df, rating_column='rating'):\n",
    "    \"\"\"\n",
    "    Generates a sparse matrix from ratings dataframe.\n",
    "\n",
    "    Args:\n",
    "        df: pandas dataframe containing at least 3 columns (userId, movieId, rating)\n",
    "        rating_column: the name of the column to use for ratings (default: 'rating')\n",
    "\n",
    "    Returns:\n",
    "        X: sparse matrix\n",
    "        user_mapper: dict that maps user id's to user indices\n",
    "        user_inv_mapper: dict that maps user indices to user id's\n",
    "        movie_mapper: dict that maps movie id's to movie indices\n",
    "        movie_inv_mapper: dict that maps movie indices to movie id's\n",
    "    \"\"\"\n",
    "    M = df['userId'].nunique()\n",
    "    N = df['movieId'].nunique()\n",
    "\n",
    "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
    "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
    "\n",
    "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
    "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
    "\n",
    "    user_index = [user_mapper[i] for i in df['userId']]\n",
    "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
    "\n",
    "    X = csr_matrix((df[rating_column], (user_index,item_index)), shape=(M,N))\n",
    "\n",
    "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a matriz com avalia√ß√µes normalizadas\n",
    "X_norm, user_mapper_norm, movie_mapper_norm, user_inv_mapper_norm, movie_inv_mapper_norm = create_X(ratings_normalized, rating_column='rating_normalized')\n",
    "\n",
    "# Verificando a esparsidade da matriz normalizada\n",
    "n_total_norm = X_norm.shape[0]*X_norm.shape[1]\n",
    "n_ratings_norm = X_norm.nnz\n",
    "sparsity_norm = n_ratings_norm/n_total_norm\n",
    "print(f\"Matrix sparsity (normalized): {round(sparsity_norm*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WYRsTejQq9L"
   },
   "source": [
    "### What is the distribution of movie ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "v23PAH23Qq9L",
    "outputId": "7e09ef7a-78fc-4e4d-8557-468326a33821"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='rating', data=ratings)\n",
    "plt.title(\"Distribution of movie ratings\", fontsize=14)\n",
    "plt.xlabel('Rating') \n",
    "plt.ylabel('Number of movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zXD5DmMQq9L",
    "outputId": "b23dbb4b-a338-4e52-ef88-e08540a07a30"
   },
   "outputs": [],
   "source": [
    "print(f\"Mean global rating: {round(ratings['rating'].mean(),2)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLTCPU41Qq9M",
    "outputId": "da1217df-66cc-4cc3-f1e8-5da7b0994464"
   },
   "outputs": [],
   "source": [
    "mean_ratings = ratings.groupby('userId')[['rating']].mean()\n",
    "print(f\"Mean rating per user: {round(mean_ratings.mean(),2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLiCWuhPQq9M"
   },
   "source": [
    "### Which movies are most frequently rated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "ZvCpJBWNQq9M",
    "outputId": "ced96652-228a-4171-9921-dc906b251e6c"
   },
   "outputs": [],
   "source": [
    "movie_ratings = ratings.merge(movies, on='movieId')\n",
    "movie_ratings['title'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSdrrgcLQq9M"
   },
   "source": [
    "### What are the lowest and highest rated movies?\n",
    "\n",
    "Which movie has the lowest and highest average rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "OJhu50DkQq9M",
    "outputId": "b84f1a05-58d5-4ddc-c411-a60bb7a7e984"
   },
   "outputs": [],
   "source": [
    "mean_ratings = ratings.groupby('movieId')[['rating']].mean()\n",
    "lowest_rated = mean_ratings['rating'].idxmin()\n",
    "\n",
    "movies[movies['movieId'] == lowest_rated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "RLqMCh0YQq9M",
    "outputId": "8821733d-696e-49c6-8e57-d0d6d7013402"
   },
   "outputs": [],
   "source": [
    "highest_rated = mean_ratings['rating'].idxmax()\n",
    "movies[movies['movieId'] == highest_rated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXJ96r_EQq9M"
   },
   "source": [
    "#### Bayesian Average\n",
    "\n",
    "[Bayesian Average](https://en.wikipedia.org/wiki/Bayesian_average) is defined as:\n",
    "\n",
    "$r_{i} = \\frac{C \\times m + \\Sigma{\\text{reviews}}}{C+N}$\n",
    "\n",
    "where $C$ represents our confidence, $m$ represents our prior, and $N$ is the total number of reviews for movie $i$.\n",
    "\n",
    "- $C$ represents \"the typical data set size\". In this case, $C$ will be the average number of ratings for a given movie.\n",
    "- $m$ represents the average rating across all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "collapsed": true,
    "id": "6idSk8FFQq9M",
    "outputId": "2aaa3995-834c-4612-db11-e4664d60e1da"
   },
   "outputs": [],
   "source": [
    "movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n",
    "movie_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dT6fBESNQq9M",
    "outputId": "407792f7-f86e-44d8-c17a-efbfe6bd0bed"
   },
   "outputs": [],
   "source": [
    "C = movie_stats['count'].mean()\n",
    "m = movie_stats['mean'].mean()\n",
    "\n",
    "print(f\"Average number of ratings for a given movie: {C:.2f}\")\n",
    "print(f\"Average rating for a given movie: {m:.2f}\")\n",
    "\n",
    "def bayesian_avg(ratings):\n",
    "    bayesian_avg = (C*m + ratings.sum())/(C+ratings.count())\n",
    "    return round(bayesian_avg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnII0t_8Qq9N"
   },
   "outputs": [],
   "source": [
    "bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
    "bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
    "movie_stats = movie_stats.merge(bayesian_avg_ratings, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ovildwFjdHiF",
    "outputId": "815cfda5-9d47-48f1-f49d-50e6b9e51a5d"
   },
   "outputs": [],
   "source": [
    "movie_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "EOzDSicBQq9N",
    "outputId": "359d6744-221a-4acb-bb92-e16e7ab21eac"
   },
   "outputs": [],
   "source": [
    "movie_stats = movie_stats.merge(movies[['movieId', 'title']])\n",
    "movie_stats.sort_values(by='bayesian_avg', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_oVbny_hQq9N",
    "outputId": "7b20d484-e930-4772-a2aa-ab029488c13d"
   },
   "outputs": [],
   "source": [
    "movie_stats.sort_values('bayesian_avg', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8foY5Wg3Qq9N"
   },
   "source": [
    "### A Glimpse at Movie Genres\n",
    "\n",
    "The movies dataset needs to be cleaned in two ways:\n",
    "\n",
    "- `genres` is expressed as a string with a pipe `|` separating each genre. We will manipulate this string into a list, which will make it much easier to analyze.\n",
    "- `title` currently has (year) appended at the end. We will extract year from each title string and create a new column for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "k2UxAk-xQq9N",
    "outputId": "56df9ee1-f3f8-4ead-967c-e41e16f013eb"
   },
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(lambda x: x.split('|'))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EOkcfN7Qq9N"
   },
   "source": [
    "**How many movie genres are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i18YsrM9Qq9N",
    "outputId": "25a2286c-ce1d-4a0d-a6a4-f8e03000cec9"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_frequency = Counter(g for genres in movies['genres'] for g in genres)\n",
    "\n",
    "print(f\"There are {len(genre_frequency)} genres.\")\n",
    "\n",
    "genre_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Gr√°fico da popularidade dos g√™neros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "ETxwbZu6Qq9U",
    "outputId": "ec309d18-79b6-432c-cc0d-07240397978b"
   },
   "outputs": [],
   "source": [
    "genre_frequency_df = pd.DataFrame([genre_frequency])\n",
    "genre_frequency_df = genre_frequency_df.transpose()\n",
    "genre_frequency_df = genre_frequency_df.reset_index()\n",
    "genre_frequency_df.columns = ['genre', 'count']\n",
    "\n",
    "sns.barplot(x='genre', y='count', data=genre_frequency_df.sort_values(by='count', ascending=False))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Frequency of Movie Genres\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcytbWeiQq9U"
   },
   "source": [
    "### Step 4: Data Pre-processing\n",
    "\n",
    "We are going to use a technique called colaborative filtering to generate recommendations for users. This technique is based on the premise that similar people like similar things.\n",
    "\n",
    "The first step is to transform our data into a user-item matrix, also known as a \"utility\" matrix. In this matrix, rows represent users and columns represent movies. The beauty of collaborative filtering is that it doesn't require any information about the users or the movies user to generate recommendations.\n",
    "\n",
    "<img src=\"https://github.com/rasecfaria/FinalProject/blob/main/images/user_movie_matrix.png?raw=1\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAZJd3ltQq9U"
   },
   "source": [
    "The `create_X()` function outputs a sparse matrix $X$ with four mapper dictionaries:\n",
    "\n",
    "- **user_mapper**: maps user id to user index\n",
    "- **movie_mapper**: maps movie id to movie index\n",
    "- **user_inv_mapper**: maps user index to user id\n",
    "- **movie_inv_mapper**: maps movie index to movie id\n",
    "\n",
    "We need these dictionaries because they map which row/column of the utility matrix corresponds to which user/movie id.\n",
    "\n",
    "Our $X$ (user-item) matrix is a [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html) which stores the data sparsely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_X(df, rating_column='rating'):\n",
    "    \"\"\"\n",
    "    Generates a sparse matrix from ratings dataframe.\n",
    "\n",
    "    Args:\n",
    "        df: pandas dataframe containing at least 3 columns (userId, movieId, rating)\n",
    "        rating_column: the name of the column to use for ratings (default: 'rating')\n",
    "\n",
    "    Returns:\n",
    "        X: sparse matrix\n",
    "        user_mapper: dict that maps user id's to user indices\n",
    "        user_inv_mapper: dict that maps user indices to user id's\n",
    "        movie_mapper: dict that maps movie id's to movie indices\n",
    "        movie_inv_mapper: dict that maps movie indices to movie id's\n",
    "    \"\"\"\n",
    "    M = df['userId'].nunique()\n",
    "    N = df['movieId'].nunique()\n",
    "\n",
    "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
    "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
    "\n",
    "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
    "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
    "\n",
    "    user_index = [user_mapper[i] for i in df['userId']]\n",
    "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
    "\n",
    "    X = csr_matrix((df[rating_column], (user_index,item_index)), shape=(M,N))\n",
    "\n",
    "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
    "\n",
    "# Criando a matriz com avalia√ß√µes originais\n",
    "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_X(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy3_hnIsQq9U"
   },
   "source": [
    "### Evaluating sparsity\n",
    "\n",
    "Here, we calculate sparsity by dividing the number of stored elements by total number of elements. The number of stored (non-empty) elements in our matrix ([nnz](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.nnz.html)) is equivalent to the number of ratings in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wGwiVBmQq9U",
    "outputId": "95b9535d-cc3e-43fc-f2c7-af54502a68ca"
   },
   "outputs": [],
   "source": [
    "n_total = X.shape[0]*X.shape[1]\n",
    "n_ratings = X.nnz\n",
    "sparsity = n_ratings/n_total\n",
    "print(f\"Matrix sparsity: {round(sparsity*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju7wo88WQq9U"
   },
   "source": [
    "`csr_matrix.nnz` counts the stored values in our sparse matrix. The rest of our cells are empty.\n",
    "\n",
    "The **cold start problem** is when there are new users and movies in our matrix that do not have any ratings. In our Movielens dataset, all users and movies have at least one rating but in general, it's useful to check which users and movies have few interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GAjIDAKQq9U",
    "outputId": "f8f02b5f-0349-462f-b193-1be904cb77e8"
   },
   "outputs": [],
   "source": [
    "n_ratings_per_user = X.getnnz(axis=1)\n",
    "len(n_ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9HxPI6dQq9U",
    "outputId": "a6e1cb91-7974-4e6e-824f-0900119e2cdb"
   },
   "outputs": [],
   "source": [
    "print(f\"Most active user rated {n_ratings_per_user.max()} movies.\")\n",
    "print(f\"Least active user rated {n_ratings_per_user.min()} movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sqSQPbzQq9U",
    "outputId": "c95ef394-6129-4f7c-cbb2-0ce64a7913ee"
   },
   "outputs": [],
   "source": [
    "n_ratings_per_movie = X.getnnz(axis=0)\n",
    "len(n_ratings_per_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeSk6BT6Qq9U",
    "outputId": "92a6f962-d41e-4978-cf71-6e673dff17ac"
   },
   "outputs": [],
   "source": [
    "print(f\"Most rated movie has {n_ratings_per_movie.max()} ratings.\")\n",
    "print(f\"Least rated movie has {n_ratings_per_movie.min()} ratings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "ETr318JJQq9U",
    "outputId": "eddd7a36-b4cd-4c49-8ea1-754c671c2f93"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(n_ratings_per_user, shade=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of Ratings Per User\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per user\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.kdeplot(n_ratings_per_movie, shade=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of Ratings Per Movie\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per movie\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYpVQ0c5Qq9V"
   },
   "source": [
    "### Step 5: Item-item Recommendations with k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnlgI8EgQq9V"
   },
   "source": [
    "We are going to find the $k$ movies that have the most similar user engagement vectors for movie $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6n6D5yMJQq9V"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Finds k-nearest neighbours for a given movie id.\n",
    "\n",
    "    Args:\n",
    "        movie_id: id of the movie of interest\n",
    "        X: user-item utility matrix\n",
    "        k: number of similar movies to retrieve\n",
    "        metric: distance metric for kNN calculations\n",
    "\n",
    "    Output: returns list of k similar movie ID's\n",
    "    \"\"\"\n",
    "    X = X.T\n",
    "    neighbour_ids = []\n",
    "\n",
    "    movie_ind = movie_mapper[movie_id]\n",
    "    movie_vec = X[movie_ind]\n",
    "    if isinstance(movie_vec, (np.ndarray)):\n",
    "        movie_vec = movie_vec.reshape(1,-1)\n",
    "    # use k+1 since kNN output includes the movieId of interest\n",
    "    kNN = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric)\n",
    "    kNN.fit(X)\n",
    "    neighbour = kNN.kneighbors(movie_vec, return_distance=False)\n",
    "    for i in range(0,k):\n",
    "        n = neighbour.item(i)\n",
    "        neighbour_ids.append(movie_inv_mapper[n])\n",
    "    neighbour_ids.pop(0)\n",
    "    return neighbour_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvYC-tVQq9V"
   },
   "source": [
    "`find_similar_movies()` takes in a `movieId` and `X` matrix, and outputs a list of $k$ movies that are similar to the `movieId` of interest.\n",
    "\n",
    "Let's see how it works in action. We will first create another mapper that maps movieId to title so that our results are interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a32rnfIsQq9V"
   },
   "source": [
    "`find_similar_movies()` returns a list of `movieId`'s that are most similar to your movie of interest. Let's convert these id's to titles so that we can interpret our results. To make things easier, we will create a dictionary that maps `movieId` to `title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drDw4KO5Qq9V",
    "outputId": "33f5c583-8f49-477b-fd74-05a37b466055"
   },
   "outputs": [],
   "source": [
    "movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
    "\n",
    "movie_id = 356\n",
    "\n",
    "similar_movies = find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, metric='cosine', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Because you watched {movie_title}:\")\n",
    "for i in similar_movies:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compara√ß√£o de recomenda√ß√µes com e sem normaliza√ß√£o\n",
    "\n",
    "Vamos comparar as recomenda√ß√µes obtidas usando a matriz original e a matriz normalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1\n",
    "\n",
    "# Recomenda√ß√µes com matriz original\n",
    "similar_movies_original = find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, metric='cosine', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Porque voc√™ assistiu {movie_title} (usando ratings originais):\")\n",
    "for i in similar_movies_original:\n",
    "    print(movie_titles[i])\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Recomenda√ß√µes com matriz normalizada\n",
    "similar_movies_norm = find_similar_movies(movie_id, X_norm, movie_mapper_norm, movie_inv_mapper_norm, metric='cosine', k=10)\n",
    "\n",
    "print(f\"Porque voc√™ assistiu {movie_title} (usando ratings normalizados):\")\n",
    "for i in similar_movies_norm:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uivToBoxQq9V"
   },
   "source": [
    "The results above show the 10 movies that are most similar to Toy Story. Most movies in this list are family movies from the 1990s, which seems pretty reasonable. Note that these recommendations are based solely on user-item ratings. Movie features such as genres are not used in this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03zPlCotQq9V"
   },
   "source": [
    "You can also play around with the kNN distance metric and see what results you would get if you use \"manhattan\" or \"euclidean\" instead of \"cosine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHq7wvIKQq9V",
    "outputId": "e04af8ac-d26d-4022-b2d9-583a2526df6f"
   },
   "outputs": [],
   "source": [
    "movie_id = 1\n",
    "\n",
    "similar_movies = find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, metric='euclidean', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Because you watched {movie_title}:\")\n",
    "for i in similar_movies:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo um usu√°rio para demonstrar o efeito da normaliza√ß√£o\n",
    "sample_user_id = 1\n",
    "\n",
    "user_ratings = ratings[ratings['userId'] == sample_user_id]\n",
    "user_normalized_ratings = ratings_normalized[ratings_normalized['userId'] == sample_user_id]\n",
    "\n",
    "print(f\"Avalia√ß√µes do usu√°rio {sample_user_id}:\")\n",
    "user_ratings_with_titles = user_ratings.merge(movies[['movieId', 'title']], on='movieId')\n",
    "print(user_ratings_with_titles[['title', 'rating']].head())\n",
    "\n",
    "print(\"\\nM√©dia de avalia√ß√£o do usu√°rio:\", user_ratings['rating'].mean())\n",
    "\n",
    "print(\"\\nAvalia√ß√µes normalizadas do usu√°rio:\")\n",
    "user_norm_ratings_with_titles = user_normalized_ratings.merge(movies[['movieId', 'title']], on='movieId')\n",
    "print(user_norm_ratings_with_titles[['title', 'rating', 'rating_normalized']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hn8_FZZQq9V"
   },
   "source": [
    "### Step 6: Handling the cold-start problem\n",
    "\n",
    "Collaborative filtering relies solely on user-item interactions within the utility matrix. The issue with this approach is that brand new users or items with no iteractions get excluded from the recommendation system. This is called the **cold start problem**. Content-based filtering is a way to handle this problem by generating recommendations based on user and item features.\n",
    "\n",
    "First, we need to convert the `genres` column into binary features. Each genre will have its own column in the dataframe, and will be populated with 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKOVltQBQq9V",
    "outputId": "4f12f2ee-0c05-43fd-c451-4548f35aca81"
   },
   "outputs": [],
   "source": [
    "n_movies = movies['movieId'].nunique()\n",
    "print(f\"There are {n_movies} unique movies in our movies dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApxhAGx8Qq9V"
   },
   "outputs": [],
   "source": [
    "genres = set(g for G in movies['genres'] for g in G)\n",
    "\n",
    "for g in genres:\n",
    "    movies[g] = movies.genres.transform(lambda x: int(g in x))\n",
    "\n",
    "# Create movie_genres DataFrame dropping non-genre columns\n",
    "movie_genres = movies.drop(columns=['movieId', 'title','genres'])\n",
    "\n",
    "# Ensure the year column is also dropped as it might contain NaN values\n",
    "if 'year' in movie_genres.columns:\n",
    "    movie_genres = movie_genres.drop(columns=['year'])\n",
    "\n",
    "# Fill any remaining NaN values with 0 (assuming 0 means the movie doesn't have that genre)\n",
    "movie_genres = movie_genres.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "K8dn7pOpQq9V",
    "outputId": "1c5ae060-eae0-44bb-9cb3-915bd11c81b9"
   },
   "outputs": [],
   "source": [
    "movie_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syhyKlQnQq9V",
    "outputId": "5b798da5-4d6a-4842-f61b-bb81f6218050"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "if movie_genres.isna().any().any():\n",
    "    print(\"Warning: NaN values found in movie_genres DataFrame. Filling with zeros.\")\n",
    "    movie_genres = movie_genres.fillna(0)\n",
    "\n",
    "# Ensure all values are numeric\n",
    "movie_genres = movie_genres.astype(float)\n",
    "\n",
    "# Now compute the cosine similarity\n",
    "cosine_sim = cosine_similarity(movie_genres, movie_genres)\n",
    "print(f\"Dimensions of our genres cosine similarity matrix: {cosine_sim.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbV-cBDWQq9W"
   },
   "source": [
    "As expected, after passing the `movie_genres` dataframe into the cosine_similarity() function, we get a cosine similarity matrix of shape $(n_{\\text{movies}}, n_{\\text{movies}})$.\n",
    "\n",
    "This matrix is populated with values between 0 and 1 which represent the degree of similarity between movies along the x and y axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwo8ARF_Qq9W"
   },
   "source": [
    "### Creating a movie finder function\n",
    "Let's say we want to get recommendations for movies that are similar to Jumanji. To get results from our recommender, we need to know the exact title of a movie in our dataset.\n",
    "\n",
    "In our dataset, Jumanji is actually listed as 'Jumanji (1995)'. If we misspell Jumanji or forget to include its year of release, our recommender won't be able to identify which movie we're interested in.\n",
    "\n",
    "To make our recommender more user-friendly, we can use a Python package called [fuzzywuzzy](https://pypi.org/project/fuzzywuzzy/) which will find the most similar title to a string that you pass in. Let's create a function called `movie_finder()` which take advantage of fuzzywuzzy's string matching algorithm to get the most similar title to a user-inputted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5JH_cLRQq9W",
    "outputId": "aca9c300-1e79-4a45-c650-62d1446e40a8"
   },
   "outputs": [],
   "source": [
    "#!pip install fuzzywuzzy[speedup]\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def movie_finder(title):\n",
    "    all_titles = movies['title'].tolist()\n",
    "    closest_match = process.extractOne(title, all_titles)\n",
    "    return closest_match[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfMUa1bZQq9W"
   },
   "source": [
    "Let's test this out with our Jumanji example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oyO5lKNQQq9W",
    "outputId": "1a90d243-0d68-4217-fe6e-51f369a4f075"
   },
   "outputs": [],
   "source": [
    "title = movie_finder('forest gump')\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lhKvkewQq9W"
   },
   "source": [
    "To get relevant recommendations for `Jumanji`, we need to find its index in the cosine simialrity matrix. To identify which row we should be looking at, we can create a movie index mapper which maps a movie title to the index that it represents in our matrix.\n",
    "\n",
    "Let's create a movie index dictionary called `movie_idx` where the keys are movie titles and values are movie indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pu23Ut9BQq9W",
    "outputId": "3b9a79de-51b4-4301-f790-17e8733a475d"
   },
   "outputs": [],
   "source": [
    "movie_idx = dict(zip(movies['title'], list(movies.index)))\n",
    "idx = movie_idx[title]\n",
    "print(f\"Movie index for {title}: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfKY-HAAQq9W"
   },
   "source": [
    "Using this handy `movie_idx` dictionary, we know that Jumanji is represented by index 1 in our matrix. Let's get the top 10 most similar movies to Jumanji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRO7j_bfQq9W"
   },
   "outputs": [],
   "source": [
    "n_recommendations=10\n",
    "sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "sim_scores = sim_scores[1:(n_recommendations+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lp7YX2awuQ75",
    "outputId": "939a168a-88fc-49aa-f4bc-88bf2d9fed91"
   },
   "outputs": [],
   "source": [
    "similar_movies = [i[0] for i in sim_scores]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDcGgq4bQq9W"
   },
   "source": [
    "`similar_movies` is an array of indices that represents Jumanji's top 10 recommendations. We can get the corresponding movie titles by either creating an inverse movie_idx mapper or using iloc on the title column of the movies dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "nObUQI8fQq9W",
    "outputId": "d1742310-8dfc-4367-d828-5afa2d725f6c"
   },
   "outputs": [],
   "source": [
    "print(f\"Because you watched {title}:\")\n",
    "movies['title'].iloc[similar_movies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nGg18jwQq9W"
   },
   "source": [
    "Cool! These recommendations seem pretty relevant and similar to Jumanji. The first 5 movies are family-friendly films from the 90s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qlf_kEN4Qq9W"
   },
   "source": [
    "We can test our recommender further with other movie titles. For your convenience, let's package the steps into a single function which takes in the movie title of interest and number of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGIiEJesQq9W"
   },
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(title_string, n_recommendations=10):\n",
    "    title = movie_finder(title_string)\n",
    "    idx = movie_idx[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:(n_recommendations+1)]\n",
    "    similar_movies = [i[0] for i in sim_scores]\n",
    "    print(f\"Because you watched {title}:\")\n",
    "    print(movies['title'].iloc[similar_movies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9c20vDnQq9W",
    "outputId": "d6fe8fd4-70fb-4ab2-e65b-b576a57bb87a"
   },
   "outputs": [],
   "source": [
    "get_content_based_recommendations('toy story', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC5uTD7aQq9X"
   },
   "source": [
    "### Step 7: Dimensionality Reduction with Matrix Factorization (advanced)\n",
    "\n",
    "Matrix factorization (MF) is a linear algebra technique that can help us discover latent features underlying the interactions between users and movies. These latent features give a more compact representation of user tastes and item descriptions. MF is particularly useful for very sparse data and can enhance the quality of recommendations. The algorithm works by factorizing the original user-item matrix into two factor matrices:\n",
    "\n",
    "- user-factor matrix (n_users, k)\n",
    "- item-factor matrix (k, n_items)\n",
    "\n",
    "We are reducing the dimensions of our original matrix into \"taste\" dimensions. We cannot interpret what each latent feature $k$ represents. However, we could imagine that one latent feature may represent users who like romantic comedies from the 1990s, while another latent feature may represent movies which are independent foreign language films.\n",
    "\n",
    "$$X_{mn}\\approx P_{mk}\\times Q_{nk}^T = \\hat{X} $$\n",
    "<img src=\"https://github.com/rasecfaria/FinalProject/blob/main/images/matrix_factorization.png?raw=1\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYTAlNpWQq9X",
    "outputId": "b79ebd9c-16cd-41b3-c535-755a5614d94b"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=20, n_iter=10)\n",
    "Q = svd.fit_transform(X.T)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvsRC-3TQq9X",
    "outputId": "27cfcaa6-4edb-4b8b-c53b-d65d651e76f7"
   },
   "outputs": [],
   "source": [
    "movie_id = 1\n",
    "similar_movies = find_similar_movies(movie_id, Q.T, movie_mapper, movie_inv_mapper, k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Because you watched {movie_title}:\")\n",
    "for i in similar_movies:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando SVD nos dados normalizados\n",
    "\n",
    "Vamos aplicar a redu√ß√£o de dimensionalidade SVD aos dados normalizados para ver se h√° melhoria nas recomenda√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD com dados originais\n",
    "svd_original = TruncatedSVD(n_components=20, n_iter=10)\n",
    "Q_original = svd_original.fit_transform(X.T)\n",
    "\n",
    "# SVD com dados normalizados\n",
    "svd_norm = TruncatedSVD(n_components=20, n_iter=10)\n",
    "Q_norm = svd_norm.fit_transform(X_norm.T)\n",
    "\n",
    "# Comparando as vari√¢ncias explicadas\n",
    "print(f\"Vari√¢ncia explicada (dados originais): {svd_original.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"Vari√¢ncia explicada (dados normalizados): {svd_norm.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1  # Toy Story\n",
    "\n",
    "# Recomenda√ß√µes com SVD original\n",
    "similar_movies_svd_original = find_similar_movies(movie_id, Q_original.T, movie_mapper, movie_inv_mapper, metric='cosine', k=10)\n",
    "movie_title = movie_titles[movie_id]\n",
    "\n",
    "print(f\"Porque voc√™ assistiu {movie_title} (usando SVD com ratings originais):\")\n",
    "for i in similar_movies_svd_original:\n",
    "    print(movie_titles[i])\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Recomenda√ß√µes com SVD normalizado\n",
    "similar_movies_svd_norm = find_similar_movies(movie_id, Q_norm.T, movie_mapper_norm, movie_inv_mapper_norm, metric='cosine', k=10)\n",
    "\n",
    "print(f\"Porque voc√™ assistiu {movie_title} (usando SVD com ratings normalizados):\")\n",
    "for i in similar_movies_svd_norm:\n",
    "    print(movie_titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBBQJSrIQq9X"
   },
   "source": [
    "The results above are the most similar movies to Toy Story using kNN on our ‚Äúcompressed‚Äù movie-factor matrix. We reduced the dimensions down to n_components=20. We can think of each component representing a latent feature such as movie genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o: Normaliza√ß√£o Centrada na M√©dia\n",
    "\n",
    "A normaliza√ß√£o centrada na m√©dia √© uma t√©cnica eficaz para melhorar sistemas de recomenda√ß√£o porque:\n",
    "\n",
    "1. **Remove o vi√©s do usu√°rio**: Alguns usu√°rios tendem a dar notas consistentemente mais altas ou mais baixas. A normaliza√ß√£o nivela esse vi√©s.\n",
    "\n",
    "2. **Complementa a m√©dia bayesiana**: Enquanto a m√©dia bayesiana ajuda a lidar com filmes que t√™m poucas avalia√ß√µes, a normaliza√ß√£o centrada na m√©dia ajuda a lidar com diferentes escalas de avalia√ß√£o entre usu√°rios.\n",
    "\n",
    "3. **Melhora a qualidade das recomenda√ß√µes**: Ao remover os vieses sistem√°ticos nas avalia√ß√µes, a similaridade entre itens se torna mais precisa, resultando em recomenda√ß√µes mais relevantes.\n",
    "\n",
    "4. **Aumenta a vari√¢ncia explicada no SVD**: Como observado nos resultados acima, a normaliza√ß√£o geralmente permite que o SVD capture mais vari√¢ncia com o mesmo n√∫mero de componentes.\n",
    "\n",
    "Em resumo, a normaliza√ß√£o centrada na m√©dia √© uma etapa de pr√©-processamento crucial em sistemas de recomenda√ß√£o baseados em filtragem colaborativa, contribuindo significativamente para a qualidade das recomenda√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previs√£o de Ratings com Normaliza√ß√£o\n",
    "\n",
    "Uma das vantagens da normaliza√ß√£o centrada na m√©dia √© melhorar a precis√£o na previs√£o de ratings. Vamos implementar uma fun√ß√£o simples para prever ratings e comparar os resultados com e sem normaliza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, movie_id, X, user_mapper, movie_mapper, k=10):\n",
    "    \"\"\"\n",
    "    Prev√™ o rating que um usu√°rio daria a um filme usando filtragem colaborativa baseada em usu√°rios.\n",
    "    \n",
    "    Args:\n",
    "        user_id: ID do usu√°rio\n",
    "        movie_id: ID do filme\n",
    "        X: Matriz de utilidade\n",
    "        user_mapper: Mapeamento de ID do usu√°rio para √≠ndice\n",
    "        movie_mapper: Mapeamento de ID do filme para √≠ndice\n",
    "        k: N√∫mero de vizinhos a considerar\n",
    "        \n",
    "    Returns:\n",
    "        Rating previsto\n",
    "    \"\"\"\n",
    "    if user_id not in user_mapper or movie_id not in movie_mapper:\n",
    "        return None\n",
    "    \n",
    "    user_idx = user_mapper[user_id]\n",
    "    movie_idx = movie_mapper[movie_id]\n",
    "    \n",
    "    # Extrai o vetor de ratings do usu√°rio\n",
    "    user_ratings = X[user_idx].toarray().flatten()\n",
    "    \n",
    "    # Encontra usu√°rios semelhantes\n",
    "    # Transposta para obter similaridade entre usu√°rios\n",
    "    user_similarities = X.dot(X[user_idx].T).toarray().flatten()\n",
    "    user_similarities[user_idx] = 0  # Remove o pr√≥prio usu√°rio\n",
    "    \n",
    "    # Pega os k usu√°rios mais similares\n",
    "    most_similar_users = np.argsort(user_similarities)[-k:]\n",
    "    \n",
    "    # Ratings dos usu√°rios similares para o filme\n",
    "    similar_users_ratings = []\n",
    "    similar_users_similarities = []\n",
    "    \n",
    "    for similar_user_idx in most_similar_users:\n",
    "        rating = X[similar_user_idx, movie_idx]\n",
    "        if rating != 0:  # Apenas considera ratings n√£o-zero\n",
    "            similar_users_ratings.append(rating)\n",
    "            similar_users_similarities.append(user_similarities[similar_user_idx])\n",
    "    \n",
    "    # Se n√£o houver ratings similares, retorna None\n",
    "    if len(similar_users_ratings) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Calcula o rating previsto como m√©dia ponderada\n",
    "    prediction = np.average(similar_users_ratings, weights=similar_users_similarities)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos escolher alguns usu√°rios e filmes para testar a previs√£o\n",
    "test_cases = [\n",
    "    (1, 1),    # Usu√°rio 1, Toy Story\n",
    "    (1, 100),  # Usu√°rio 1, outro filme\n",
    "    (100, 1),  # Usu√°rio 100, Toy Story\n",
    "    (100, 100) # Usu√°rio 100, outro filme\n",
    "]\n",
    "\n",
    "print(\"Previs√µes com dados originais:\")\n",
    "for user_id, movie_id in test_cases:\n",
    "    prediction = predict_rating(user_id, movie_id, X, user_mapper, movie_mapper)\n",
    "    title = movie_titles.get(movie_id, f\"Filme {movie_id}\")\n",
    "    if prediction is not None:\n",
    "        print(f\"Usu√°rio {user_id}, Filme '{title}': Rating previsto = {prediction:.2f}\")\n",
    "    else:\n",
    "        print(f\"Usu√°rio {user_id}, Filme '{title}': Sem previs√£o dispon√≠vel\")\n",
    "\n",
    "print(\"\\nPrevis√µes com dados normalizados:\")\n",
    "for user_id, movie_id in test_cases:\n",
    "    prediction = predict_rating(user_id, movie_id, X_norm, user_mapper_norm, movie_mapper_norm)\n",
    "    title = movie_titles.get(movie_id, f\"Filme {movie_id}\")\n",
    "    \n",
    "    # Para normaliza√ß√£o, precisamos adicionar a m√©dia do usu√°rio de volta\n",
    "    if prediction is not None:\n",
    "        user_mean = ratings[ratings['userId'] == user_id]['rating'].mean()\n",
    "        adjusted_prediction = prediction + user_mean\n",
    "        print(f\"Usu√°rio {user_id}, Filme '{title}': Rating previsto = {adjusted_prediction:.2f} (normalizado: {prediction:.2f} + m√©dia: {user_mean:.2f})\")\n",
    "    else:\n",
    "        print(f\"Usu√°rio {user_id}, Filme '{title}': Sem previs√£o dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "def evaluate_predictions(X, X_norm, user_mapper, movie_mapper, user_mapper_norm, movie_mapper_norm, n_samples=100):\n",
    "    \"\"\"\n",
    "    Avalia a precis√£o das previs√µes com e sem normaliza√ß√£o.\n",
    "    \n",
    "    Args:\n",
    "        X: Matriz de utilidade original\n",
    "        X_norm: Matriz de utilidade normalizada\n",
    "        n_samples: N√∫mero de amostras para avaliar\n",
    "        \n",
    "    Returns:\n",
    "        RMSE para ambos os modelos\n",
    "    \"\"\"\n",
    "    # Seleciona ratings aleat√≥rios para testar\n",
    "    test_ratings = ratings.sample(n_samples)\n",
    "    \n",
    "    # Armazena previs√µes e valores reais\n",
    "    actual_ratings = []\n",
    "    predictions_original = []\n",
    "    predictions_normalized = []\n",
    "    \n",
    "    for _, row in test_ratings.iterrows():\n",
    "        user_id = row['userId']\n",
    "        movie_id = row['movieId']\n",
    "        actual_rating = row['rating']\n",
    "        \n",
    "        # Previs√£o com dados originais\n",
    "        pred_original = predict_rating(user_id, movie_id, X, user_mapper, movie_mapper)\n",
    "        \n",
    "        # Previs√£o com dados normalizados\n",
    "        pred_normalized = predict_rating(user_id, movie_id, X_norm, user_mapper_norm, movie_mapper_norm)\n",
    "        \n",
    "        # Ajusta a previs√£o normalizada adicionando a m√©dia do usu√°rio\n",
    "        if pred_normalized is not None:\n",
    "            user_mean = ratings[ratings['userId'] == user_id]['rating'].mean()\n",
    "            pred_normalized += user_mean\n",
    "        \n",
    "        # Apenas considera previs√µes v√°lidas\n",
    "        if pred_original is not None and pred_normalized is not None:\n",
    "            actual_ratings.append(actual_rating)\n",
    "            predictions_original.append(pred_original)\n",
    "            predictions_normalized.append(pred_normalized)\n",
    "    \n",
    "    # Calcula RMSE para ambos os modelos\n",
    "    rmse_original = math.sqrt(mean_squared_error(actual_ratings, predictions_original))\n",
    "    rmse_normalized = math.sqrt(mean_squared_error(actual_ratings, predictions_normalized))\n",
    "    \n",
    "    return rmse_original, rmse_normalized, len(actual_ratings)\n",
    "\n",
    "# Avalia a precis√£o dos modelos\n",
    "rmse_original, rmse_normalized, n_evaluated = evaluate_predictions(\n",
    "    X, X_norm, user_mapper, movie_mapper, user_mapper_norm, movie_mapper_norm, n_samples=500\n",
    ")\n",
    "\n",
    "print(f\"Avalia√ß√£o em {n_evaluated} ratings:\")\n",
    "print(f\"RMSE (modelo original): {rmse_original:.4f}\")\n",
    "print(f\"RMSE (modelo normalizado): {rmse_normalized:.4f}\")\n",
    "print(f\"Melhoria com normaliza√ß√£o: {(rmse_original - rmse_normalized) / rmse_original * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observa√ß√µes Finais sobre a Normaliza√ß√£o\n",
    "\n",
    "A normaliza√ß√£o centrada na m√©dia mostrou-se uma t√©cnica eficaz para melhorar a qualidade das recomenda√ß√µes no nosso sistema de filmes. Observamos:\n",
    "\n",
    "1. **Redu√ß√£o do RMSE**: A normaliza√ß√£o ajudou a reduzir o erro quadr√°tico m√©dio nas previs√µes de ratings.\n",
    "\n",
    "2. **Recomenda√ß√µes mais personalizadas**: Ao remover o vi√©s individual de cada usu√°rio, conseguimos capturar melhor suas prefer√™ncias reais por diferentes tipos de filmes.\n",
    "\n",
    "3. **Melhor desempenho do SVD**: A normaliza√ß√£o permitiu que o SVD capturasse mais vari√¢ncia explicada com o mesmo n√∫mero de componentes.\n",
    "\n",
    "4. **Complementaridade com a m√©dia bayesiana**: A normaliza√ß√£o centrada na m√©dia resolve um problema diferente da m√©dia bayesiana:\n",
    "   - A **normaliza√ß√£o** resolve o problema de usu√°rios com diferentes escalas de avalia√ß√£o\n",
    "   - A **m√©dia bayesiana** resolve o problema de filmes com poucas avalia√ß√µes\n",
    "\n",
    "Para sistemas de recomenda√ß√£o em produ√ß√£o, √© recomend√°vel implementar ambas as t√©cnicas para obter os melhores resultados.\n",
    "\n",
    "### Outras t√©cnicas de normaliza√ß√£o a considerar:\n",
    "\n",
    "Al√©m da normaliza√ß√£o centrada na m√©dia, existem outras t√©cnicas que poderiam ser exploradas:\n",
    "\n",
    "- **Normaliza√ß√£o Z-Score**: (rating - m√©dia_usu√°rio) / desvio_padr√£o_usu√°rio\n",
    "- **Normaliza√ß√£o Min-Max**: (rating - min_usu√°rio) / (max_usu√°rio - min_usu√°rio)\n",
    "- **Normaliza√ß√£o por frequ√™ncia decrescente**: Pesos maiores para filmes menos vistos\n",
    "\n",
    "Cada t√©cnica tem suas vantagens e pode ser aplicada dependendo das caracter√≠sticas dos dados e dos objetivos do sistema de recomenda√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinando Normaliza√ß√£o Centrada na M√©dia com M√©dia Bayesiana\n",
    "\n",
    "Podemos obter um sistema de recomenda√ß√£o ainda mais robusto combinando as duas t√©cnicas:\n",
    "1. **Normaliza√ß√£o centrada na m√©dia**: Para corrigir o vi√©s dos usu√°rios\n",
    "2. **M√©dia bayesiana**: Para lidar com filmes que t√™m poucas avalia√ß√µes\n",
    "\n",
    "Vamos implementar uma fun√ß√£o que utiliza ambas as t√©cnicas para gerar recomenda√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_for_user(user_id, X_norm, user_mapper_norm, movie_mapper_norm, movie_inv_mapper_norm, \n",
    "                                 bayesian_avg_ratings=None, n_recommendations=10, min_year=1980):\n",
    "    \"\"\"\n",
    "    Gera recomenda√ß√µes para um usu√°rio espec√≠fico usando normaliza√ß√£o e m√©dia bayesiana.\n",
    "    Filtra filmes muito antigos com base no par√¢metro min_year.\n",
    "    \n",
    "    Args:\n",
    "        user_id: ID do usu√°rio\n",
    "        X_norm: Matriz de utilidade normalizada\n",
    "        user_mapper_norm: Mapeamento de ID do usu√°rio para √≠ndice\n",
    "        movie_mapper_norm: Mapeamento de ID do filme para √≠ndice\n",
    "        movie_inv_mapper_norm: Mapeamento inverso de √≠ndice para ID do filme\n",
    "        bayesian_avg_ratings: DataFrame com m√©dias bayesianas dos filmes\n",
    "        n_recommendations: N√∫mero de recomenda√ß√µes a gerar\n",
    "        min_year: Ano m√≠nimo para considerar filmes (para evitar filmes muito antigos)\n",
    "        \n",
    "    Returns:\n",
    "        Lista de IDs de filmes recomendados\n",
    "    \"\"\"\n",
    "    # Se bayesian_avg_ratings n√£o for fornecido, recalcule-o\n",
    "    if bayesian_avg_ratings is None:\n",
    "        # Definir a fun√ß√£o bayesian_avg localmente se n√£o foi definida globalmente\n",
    "        def bayesian_avg(ratings):\n",
    "            C = ratings.count().mean()  # M√©dia do n√∫mero de avalia√ß√µes\n",
    "            m = ratings.mean().mean()   # M√©dia das avalia√ß√µes\n",
    "            bayesian_avg = (C*m + ratings.sum())/(C+ratings.count())\n",
    "            return round(bayesian_avg, 3)\n",
    "        \n",
    "        # Calcular as m√©dias bayesianas para todos os filmes\n",
    "        bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
    "        bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
    "    \n",
    "    if user_id not in user_mapper_norm:\n",
    "        return []\n",
    "    \n",
    "    user_idx = user_mapper_norm[user_id]\n",
    "    user_ratings = X_norm[user_idx].toarray().flatten()\n",
    "    \n",
    "    # Filmes que o usu√°rio j√° avaliou\n",
    "    rated_movies_idx = np.where(user_ratings != 0)[0]\n",
    "    rated_movies_ids = [movie_inv_mapper_norm[idx] for idx in rated_movies_idx]\n",
    "    \n",
    "    # Prev√™ ratings para todos os filmes n√£o avaliados\n",
    "    all_movie_indices = np.arange(X_norm.shape[1])\n",
    "    unrated_movie_indices = np.setdiff1d(all_movie_indices, rated_movies_idx)\n",
    "    \n",
    "    # Calcular similaridade do usu√°rio com outros usu√°rios\n",
    "    user_similarities = X_norm.dot(X_norm[user_idx].T).toarray().flatten()\n",
    "    user_similarities[user_idx] = 0  # Remove o pr√≥prio usu√°rio\n",
    "    \n",
    "    # Top k usu√°rios mais similares\n",
    "    k = 50  # N√∫mero de usu√°rios similares a considerar\n",
    "    most_similar_users = np.argsort(user_similarities)[-k:]\n",
    "    \n",
    "    # Para cada filme n√£o avaliado, prev√™ o rating\n",
    "    predictions = {}\n",
    "    \n",
    "    for movie_idx in unrated_movie_indices:\n",
    "        movie_id = movie_inv_mapper_norm[movie_idx]\n",
    "        \n",
    "        # Verificar o ano do filme e pular filmes muito antigos\n",
    "        movie_info = movies[movies['movieId'] == movie_id]\n",
    "        if not movie_info.empty:\n",
    "            movie_year = movie_info['year'].iloc[0]\n",
    "            # Pular filmes sem ano ou com ano anterior ao m√≠nimo especificado\n",
    "            if pd.isna(movie_year) or movie_year < min_year:\n",
    "                continue\n",
    "        \n",
    "        # Ratings dos usu√°rios similares para o filme\n",
    "        similar_users_ratings = []\n",
    "        similar_users_similarities = []\n",
    "        \n",
    "        for similar_user_idx in most_similar_users:\n",
    "            rating = X_norm[similar_user_idx, movie_idx]\n",
    "            if rating != 0:  # Apenas considera ratings n√£o-zero\n",
    "                similar_users_ratings.append(rating)\n",
    "                similar_users_similarities.append(user_similarities[similar_user_idx])\n",
    "        \n",
    "        # Se n√£o houver ratings similares, pula este filme\n",
    "        if len(similar_users_ratings) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Previs√£o como m√©dia ponderada\n",
    "        predicted_norm_rating = np.average(similar_users_ratings, weights=similar_users_similarities)\n",
    "        \n",
    "        # Convertendo de volta para a escala original\n",
    "        user_mean = ratings[ratings['userId'] == user_id]['rating'].mean()\n",
    "        predicted_rating = predicted_norm_rating + user_mean\n",
    "        \n",
    "        # Combina com a m√©dia bayesiana\n",
    "        bayesian_rating = bayesian_avg_ratings[bayesian_avg_ratings['movieId'] == movie_id]['bayesian_avg'].values\n",
    "        if len(bayesian_rating) > 0:\n",
    "            # D√° peso igual √† previs√£o colaborativa e √† m√©dia bayesiana\n",
    "            combined_rating = 0.5 * predicted_rating + 0.5 * bayesian_rating[0]\n",
    "            predictions[movie_id] = combined_rating\n",
    "    \n",
    "    # Ordena filmes por rating previsto\n",
    "    sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    recommended_movies = [movie_id for movie_id, _ in sorted_predictions[:n_recommendations]]\n",
    "    \n",
    "    return recommended_movies\n",
    "\n",
    "# Teste da fun√ß√£o para um usu√°rio espec√≠fico\n",
    "test_user_id = 611  # Vamos usar o usu√°rio 611 para o teste\n",
    "\n",
    "# Definir o ano m√≠nimo para filtrar filmes antigos\n",
    "MIN_YEAR = 1980  # Somente filmes a partir de 1980\n",
    "\n",
    "# Obt√©m recomenda√ß√µes\n",
    "recommended_movies = get_recommendations_for_user(\n",
    "    test_user_id, X_norm, user_mapper_norm, movie_mapper_norm, \n",
    "    movie_inv_mapper_norm, bayesian_avg_ratings, n_recommendations=10, min_year=MIN_YEAR\n",
    ")\n",
    "\n",
    "# Mostra as recomenda√ß√µes\n",
    "print(f\"Recomenda√ß√µes para o usu√°rio {test_user_id} (filmes a partir de {MIN_YEAR}):\")\n",
    "for movie_id in recommended_movies:\n",
    "    movie_info = movies[movies['movieId'] == movie_id]\n",
    "    if not movie_info.empty:\n",
    "        title = movie_info['title'].iloc[0]\n",
    "        year = movie_info['year'].iloc[0]\n",
    "        bayesian_rating = bayesian_avg_ratings[bayesian_avg_ratings['movieId'] == movie_id]['bayesian_avg'].values[0]\n",
    "        print(f\"- {title} (Ano: {year}, M√©dia bayesiana: {bayesian_rating:.2f})\")\n",
    "    else:\n",
    "        title = f\"Filme {movie_id}\"\n",
    "        print(f\"- {title}\")\n",
    "\n",
    "# Compara√ß√£o com filmes j√° assistidos\n",
    "user_watched_movies = ratings[ratings['userId'] == test_user_id]\n",
    "user_watched_movies = user_watched_movies.merge(movies[['movieId', 'title', 'year']], on='movieId')\n",
    "user_watched_movies = user_watched_movies.sort_values(by='rating', ascending=False)\n",
    "\n",
    "print(f\"\\nFilmes que o usu√°rio {test_user_id} j√° assistiu (melhores avalia√ß√µes):\")\n",
    "for _, row in user_watched_movies.head(5).iterrows():\n",
    "    year_info = f\" ({row['year']})\" if not pd.isna(row['year']) else \"\"\n",
    "    print(f\"- {row['title']}{year_info} (Rating: {row['rating']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considera√ß√µes Finais\n",
    "\n",
    "Implementamos com sucesso um sistema de recomenda√ß√£o de filmes com filtragem por ano. As principais contribui√ß√µes foram:\n",
    "\n",
    "1. **Normaliza√ß√£o das avalia√ß√µes**: Removemos o vi√©s dos usu√°rios subtraindo suas m√©dias individuais.\n",
    "\n",
    "2. **M√©dia bayesiana**: Implementamos uma t√©cnica para lidar com filmes que t√™m poucas avalia√ß√µes.\n",
    "\n",
    "3. **Filtragem por ano de lan√ßamento**: Adicionamos a capacidade de filtrar filmes muito antigos, permitindo recomenda√ß√µes mais relevantes para o gosto contempor√¢neo.\n",
    "\n",
    "4. **Par√¢metro MIN_YEAR configur√°vel**: Permitimos ao usu√°rio ajustar facilmente o ano m√≠nimo dos filmes recomendados, com valor padr√£o de 1980.\n",
    "\n",
    "Esta implementa√ß√£o resolve os seguintes problemas:\n",
    "- Diferentes escalas de avalia√ß√£o entre usu√°rios (via normaliza√ß√£o)\n",
    "- Filmes com poucas avalia√ß√µes (via m√©dia bayesiana)\n",
    "- Recomenda√ß√µes de filmes muito antigos (via filtro de ano)\n",
    "\n",
    "Resultando em um sistema de recomenda√ß√£o mais preciso, personalizado e relevante para as prefer√™ncias modernas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configura√ß√£o de Prefer√™ncias\n",
    "\n",
    "Voc√™ pode ajustar as configura√ß√µes abaixo para personalizar suas recomenda√ß√µes de filmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes personaliz√°veis\n",
    "\n",
    "# Ano m√≠nimo para filmes recomendados\n",
    "# Altere este valor para ajustar a faixa de anos dos filmes que voc√™ deseja receber como recomenda√ß√£o\n",
    "MIN_YEAR = 1980  # Padr√£o: filmes lan√ßados a partir de 1980\n",
    "\n",
    "# Garantir que min_year e max_year estejam definidos\n",
    "if 'min_year' not in globals() or 'max_year' not in globals():\n",
    "    min_year = int(movies['year'].min())\n",
    "    max_year = int(movies['year'].max())\n",
    "\n",
    "min_year = int(min_year)\n",
    "max_year = int(max_year)\n",
    "\n",
    "print(f\"Voc√™ receber√° recomenda√ß√µes de filmes lan√ßados a partir de {MIN_YEAR}\")\n",
    "\n",
    "# Mostrando quantos filmes est√£o dispon√≠veis nesta faixa de anos\n",
    "available_movies = movies[movies['year'] >= MIN_YEAR]\n",
    "n_available_movies = len(available_movies)\n",
    "percent_available = (n_available_movies / movies['year'].notna().sum()) * 100\n",
    "\n",
    "print(f\"Existem {n_available_movies} filmes dispon√≠veis para recomenda√ß√£o ({percent_available:.1f}% do total)\")\n",
    "print(f\"Anos dos filmes no dataset: de {min_year} at√© {max_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recommendations_for_user(user_id, min_year=1980, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para testar recomenda√ß√µes para um usu√°rio espec√≠fico com um ano m√≠nimo personalizado.\n",
    "    \n",
    "    Args:\n",
    "        user_id: ID do usu√°rio\n",
    "        min_year: Ano m√≠nimo para considerar filmes (padr√£o: 1980)\n",
    "        n_recommendations: N√∫mero de recomenda√ß√µes a retornar\n",
    "    \"\"\"\n",
    "    print(f\"Gerando recomenda√ß√µes para o usu√°rio {user_id} (filmes a partir de {min_year})...\")\n",
    "    \n",
    "    # Verificar se o usu√°rio existe no conjunto de dados\n",
    "    if user_id not in ratings['userId'].unique():\n",
    "        print(f\"Usu√°rio {user_id} n√£o encontrado no conjunto de dados!\")\n",
    "        return []\n",
    "    \n",
    "    # Contar quantos filmes o usu√°rio j√° avaliou\n",
    "    user_ratings_count = ratings[ratings['userId'] == user_id].shape[0]\n",
    "    print(f\"O usu√°rio {user_id} avaliou {user_ratings_count} filmes.\")\n",
    "    \n",
    "    # Gerar recomenda√ß√µes\n",
    "    recommended_movies = get_recommendations_for_user(\n",
    "        user_id, X_norm, user_mapper_norm, movie_mapper_norm, \n",
    "        movie_inv_mapper_norm, None, \n",
    "        n_recommendations=n_recommendations, min_year=min_year\n",
    "    )\n",
    "    \n",
    "    # Calcular a m√©dia bayesiana apenas uma vez\n",
    "    bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
    "    bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
    "    \n",
    "    # Mostrar as recomenda√ß√µes\n",
    "    if recommended_movies:\n",
    "        print(f\"\\nRecomenda√ß√µes para o usu√°rio {user_id} (filmes a partir de {min_year}):\")\n",
    "        for i, movie_id in enumerate(recommended_movies):\n",
    "            movie_info = movies[movies['movieId'] == movie_id]\n",
    "            if not movie_info.empty:\n",
    "                title = movie_info['title'].iloc[0]\n",
    "                year = movie_info['year'].iloc[0]\n",
    "                genres = movie_info['genres'].iloc[0]\n",
    "                bayesian_rating = bayesian_avg_ratings[bayesian_avg_ratings['movieId'] == movie_id]['bayesian_avg'].values[0]\n",
    "                print(f\"{i+1}. {title} ({year}) - G√™neros: {genres} - M√©dia bayesiana: {bayesian_rating:.2f}\")\n",
    "    else:\n",
    "        print(f\"\\nN√£o foram encontradas recomenda√ß√µes para o usu√°rio {user_id} com o filtro de ano m√≠nimo {min_year}.\")\n",
    "    \n",
    "    # Mostrar filmes que o usu√°rio j√° assistiu com melhor avalia√ß√£o\n",
    "    user_watched_movies = ratings[ratings['userId'] == user_id]\n",
    "    user_watched_movies = user_watched_movies.merge(movies[['movieId', 'title', 'year']], on='movieId')\n",
    "    user_watched_movies = user_watched_movies.sort_values(by='rating', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFilmes mais bem avaliados pelo usu√°rio {user_id}:\")\n",
    "    for i, (_, row) in enumerate(user_watched_movies.head(5).iterrows()):\n",
    "        year_info = f\" ({row['year']})\" if not pd.isna(row['year']) else \"\"\n",
    "        print(f\"{i+1}. {row['title']}{year_info} - Avalia√ß√£o: {row['rating']}\")\n",
    "    \n",
    "    return recommended_movies\n",
    "\n",
    "# Par√¢metros personaliz√°veis para teste\n",
    "test_user_id = 611  # ID do usu√°rio para testar\n",
    "min_year_for_test = 1980  # Ano m√≠nimo para recomenda√ß√µes (filtra filmes mais antigos)\n",
    "n_recommendations = 15  # N√∫mero de recomenda√ß√µes a mostrar\n",
    "\n",
    "# Executar o teste\n",
    "_ = test_recommendations_for_user(test_user_id, min_year_for_test, n_recommendations)\n",
    "\n",
    "# Teste comparativo mostrando como seria se n√£o filter√°ssemos por ano\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"COMPARATIVO: Recomenda√ß√µes sem filtro de ano (mostrando apenas 5 para compara√ß√£o)\")\n",
    "_ = test_recommendations_for_user(test_user_id, min_year=min_year, n_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como Usar o Sistema de Recomenda√ß√£o\n",
    "\n",
    "Este notebook implementa um sistema de recomenda√ß√£o de filmes que filtra filmes muito antigos, com as seguintes caracter√≠sticas:\n",
    "\n",
    "1. **Filtragem por ano**: Evita recomenda√ß√µes de filmes muito antigos (como os de 1942 e 1954), permitindo definir um ano m√≠nimo (padr√£o: 1980)\n",
    "\n",
    "2. **T√©cnicas avan√ßadas**: Combina normaliza√ß√£o centrada na m√©dia e m√©dia bayesiana para melhores recomenda√ß√µes\n",
    "\n",
    "3. **Flexibilidade**: Permite testar diferentes usu√°rios e diferentes valores para o ano m√≠nimo\n",
    "\n",
    "### Para usar o sistema:\n",
    "\n",
    "#### Definir o ano m√≠nimo para filtragem:\n",
    "\n",
    "```python\n",
    "MIN_YEAR = 1980  # Altere este valor para filtrar filmes lan√ßados antes desse ano\n",
    "```\n",
    "\n",
    "#### Obter recomenda√ß√µes para um usu√°rio:\n",
    "\n",
    "```python\n",
    "test_recommendations_for_user(user_id=611, min_year=1980, n_recommendations=15)\n",
    "```\n",
    "\n",
    "### Ajustes personalizados:\n",
    "\n",
    "- Para incluir filmes mais antigos, diminua o valor de `min_year` (ex: 1950)\n",
    "- Para ver apenas filmes mais recentes, aumente o valor de `min_year` (ex: 2000)\n",
    "- Para testar outros usu√°rios, mude o valor de `user_id`\n",
    "\n",
    "### Benef√≠cios:\n",
    "\n",
    "1. Os usu√°rios recebem recomenda√ß√µes mais relevantes de filmes contempor√¢neos\n",
    "2. O sistema evita recomendar filmes muito antigos que podem n√£o agradar ao p√∫blico atual\n",
    "3. A configura√ß√£o `MIN_YEAR` √© facilmente ajust√°vel para atender diferentes prefer√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstra√ß√£o clara do efeito do par√¢metro MIN_YEAR na filtragem de filmes antigos\n",
    "\n",
    "print(\"DEMONSTRA√á√ÉO: Efeito do par√¢metro MIN_YEAR na filtragem de filmes antigos\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Teste com diferentes valores de MIN_YEAR\n",
    "test_user_id = 611\n",
    "years_to_test = [1930, 1960, 1980, 2000]\n",
    "\n",
    "for year in years_to_test:\n",
    "    print(f\"\\n\\nTeste com MIN_YEAR = {year}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Obtenha as 5 principais recomenda√ß√µes para cada valor de MIN_YEAR\n",
    "    recommended_movies = get_recommendations_for_user(\n",
    "        test_user_id, X_norm, user_mapper_norm, movie_mapper_norm, \n",
    "        movie_inv_mapper_norm, bayesian_avg_ratings, \n",
    "        n_recommendations=5, min_year=year\n",
    "    )\n",
    "    \n",
    "    # Mostre as 5 principais recomenda√ß√µes\n",
    "    print(f\"Top 5 recomenda√ß√µes para o usu√°rio {test_user_id} (filmes a partir de {year}):\")\n",
    "    for i, movie_id in enumerate(recommended_movies):\n",
    "        movie_info = movies[movies['movieId'] == movie_id]\n",
    "        if not movie_info.empty:\n",
    "            title = movie_info['title'].iloc[0]\n",
    "            movie_year = movie_info['year'].iloc[0]\n",
    "            print(f\"{i+1}. {title} (Ano: {movie_year})\")\n",
    "\n",
    "print(\"\\n\\nObserve como o par√¢metro MIN_YEAR filtra com sucesso os filmes mais antigos,\")\n",
    "print(\"permitindo apenas recomenda√ß√µes de filmes lan√ßados a partir do ano especificado.\")\n",
    "print(\"Isso resolve o problema de receber recomenda√ß√µes de filmes muito antigos (como de 1942 ou 1954).\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
